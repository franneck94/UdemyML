{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "Num features:  13\n"
     ]
    }
   ],
   "source": [
    "all_features = df.columns.values.tolist()\n",
    "num_features_total = len(all_features)\n",
    "print(all_features)\n",
    "print(\"Num features: \", num_features_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "\n",
    "<font size=\"5\">\n",
    "Test the model performance for a subset of the given dataset where you only use one feature (hence not all 13 features ;)\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featue: 0\tR2: 0.138140\n",
      "Featue: 1\tR2: 0.156386\n",
      "Featue: 2\tR2: 0.115023\n",
      "Featue: 3\tR2: 0.015996\n",
      "Featue: 4\tR2: 0.214377\n",
      "Featue: 5\tR2: 0.479388\n",
      "Featue: 6\tR2: 0.247553\n",
      "Featue: 7\tR2: -0.037431\n",
      "Featue: 8\tR2: 0.081760\n",
      "Featue: 9\tR2: 0.294857\n",
      "Featue: 10\tR2: 0.241133\n",
      "Featue: 11\tR2: 0.112641\n",
      "Featue: 12\tR2: 0.538005\n"
     ]
    }
   ],
   "source": [
    "scores: List[Tuple[int, float]] = []\n",
    "\n",
    "for feature_idx in range(num_features_total):\n",
    "    x_sliced = x[:, [feature_idx]]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_sliced, y, test_size=0.3)\n",
    "\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(x_train, y_train)\n",
    "    r2 = regr.score(x_test, y_test)\n",
    "    scores.append((feature_idx, r2))\n",
    "\n",
    "    print(f\"Featue: {feature_idx}\\tR2: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "<font size=\"5\">\n",
    "Plot the standard deviation, and variance of each feature.\n",
    "Do these values correlate to the performance differences from exercise 1?\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 0.5380052327556762), (5, 0.4793882936184912), (9, 0.2948573932208305), (6, 0.24755265367990642), (10, 0.24113282841490136), (4, 0.21437745037434752), (1, 0.15638621004081643), (0, 0.1381400841713265), (2, 0.11502275985265009), (11, 0.1126411704301381), (8, 0.08176044033536023), (3, 0.015996439988834488), (7, -0.03743139263865247)]\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(sorted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 12\tScore: 0.538005\tStd: 7.1340\tVar: 50.8940\n",
      "Feature: 5\tScore: 0.479388\tStd: 0.7019\tVar: 0.4927\n",
      "Feature: 9\tScore: 0.294857\tStd: 168.3705\tVar: 28348.6236\n",
      "Feature: 6\tScore: 0.247553\tStd: 28.1210\tVar: 790.7925\n",
      "Feature: 10\tScore: 0.241133\tStd: 2.1628\tVar: 4.6777\n",
      "Feature: 4\tScore: 0.214377\tStd: 0.1158\tVar: 0.0134\n",
      "Feature: 1\tScore: 0.156386\tStd: 23.2994\tVar: 542.8618\n",
      "Feature: 0\tScore: 0.138140\tStd: 8.5930\tVar: 73.8404\n",
      "Feature: 2\tScore: 0.115023\tStd: 6.8536\tVar: 46.9714\n",
      "Feature: 11\tScore: 0.112641\tStd: 91.2046\tVar: 8318.2804\n",
      "Feature: 8\tScore: 0.081760\tStd: 8.6987\tVar: 75.6665\n",
      "Feature: 3\tScore: 0.015996\tStd: 0.2537\tVar: 0.0644\n",
      "Feature: 7\tScore: -0.037431\tStd: 2.1036\tVar: 4.4253\n"
     ]
    }
   ],
   "source": [
    "for feature_idx, score in sorted_scores:\n",
    "    x_sliced = x[:, [feature_idx]]\n",
    "    std = np.std(x_sliced)\n",
    "    var = np.var(x_sliced)\n",
    "\n",
    "    print(f\"Feature: {feature_idx}\\tScore: {score:.6f}\\tStd: {std:.4f}\\tVar: {var:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26eab8343ce5ed02de4098c10e314ebb45ce0ac5e34fea85423d6f141bc9ca67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
